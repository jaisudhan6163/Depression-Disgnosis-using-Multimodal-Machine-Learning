{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalLSTM(nn.Module):\n",
    "    def __init__(self, text_modal, audio_modal, video_modal, hidden_size, output_size):\n",
    "        super(MultimodalLSTM, self).__init__()\n",
    "        self.text_layer = nn.LSTM(input_size=text_modal, hidden_size=hidden_size, batch_first=True)\n",
    "        self.audio_layer = nn.LSTM(input_size=audio_modal, hidden_size=hidden_size, batch_first=True)\n",
    "        self.video_layer = nn.LSTM(input_size=video_modal, hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * 3, output_size)\n",
    "\n",
    "    def forward(self, x1, x2, x3):\n",
    "        _, (h1, _) = self.text_layer(x1)\n",
    "        _, (h2, _) = self.audio_layer(x2)\n",
    "        _, (h3, _) = self.video_layer(x3)\n",
    "        combined = torch.cat((h1[-1], h2[-1], h3[-1]), dim=0)\n",
    "        output = torch.sigmoid(self.fc(combined))\n",
    "        return float(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to make predictions with the model\n",
    "def make_predictions(input_data1, input_data2, input_data3):\n",
    "    # Load the model\n",
    "    model = MultimodalLSTM(300, 74, 388, 64, 1)\n",
    "    model.load_state_dict(torch.load('./models/multimodal_lstm_model_10_epochs.pth'))\n",
    "    model.eval()\n",
    "\n",
    "    # Make predictions with the model\n",
    "    output = model(input_data1, input_data2, input_data3)\n",
    "\n",
    "    # Return the predictions\n",
    "    return output\n",
    "\n",
    "# Example usage:\n",
    "input_data2 = torch.randn(1000, 74)  # Replace with your input data\n",
    "input_data3 = torch.randn(1000, 388)  # Replace with your input data\n",
    "\n",
    "output = make_predictions(text, input_data2, input_data3)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from text_processing import return_tensor\n",
    "\n",
    "return_tensor(pd.read_csv('./daic_woz/dev_data/302/302_TRANSCRIPT.csv', delimiter = '\\t', encoding='utf-8', engine='python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from audio_processing import return_tensor\n",
    "\n",
    "return_tensor(pd.read_csv('./daic_woz/dev_data/302/302_COVAREP.csv', header = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def processData(data):\n",
    "    X = data.iloc[:,:].values\n",
    "    X = np.delete(X, 0, 1)\n",
    "    X = np.delete(X, 1, 1)\n",
    "    for i in range(len(X)):\n",
    "        if(isinstance(X[i][5],str) or isinstance(X[i][7],str)):\n",
    "            X[i] = np.zeros((1, X.shape[1]))\n",
    "    return X\n",
    "\n",
    "def scale_down(X):\n",
    "  X_new = []\n",
    "  size = 2\n",
    "  for i in range(int(X.shape[0]/size)):\n",
    "    cur_row = X[i*size]\n",
    "    for j in range(1,size):\n",
    "      if(i+j < X.shape[0]):\n",
    "        cur_row += X[i+j]\n",
    "    cur_row = cur_row/size\n",
    "    X_new.append(cur_row)\n",
    "  X_new = np.array(X_new)\n",
    "  return X_new\n",
    "\n",
    "def decrease_size(X):\n",
    "  size = 1000\n",
    "  if(X.shape[0] < size):\n",
    "    dif = size - X.shape[0] \n",
    "    temp = np.zeros((dif,X.shape[1]))\n",
    "    X = np.concatenate((X,temp),axis = 0)\n",
    "  elif(X.shape[0] > size):\n",
    "    X = X[:1000, :]\n",
    "  return X\n",
    "\n",
    "def prcs_video(au, feat, feat3d, gaze, pose):\n",
    "    vid = np.concatenate((au, feat, feat3d, gaze, pose), 1)\n",
    "    vid = scale_down(vid)\n",
    "    vid = decrease_size(vid)\n",
    "    return vid\n",
    "\n",
    "def return_tensor(au, feat, feat3d, gaze, pose):\n",
    "   return torch.tensor(prcs_video(au, feat, feat3d, gaze, pose)).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "au = processData(pd.read_csv('./daic_woz/dev_data/302/302_CLNF_AUs.txt', delimiter = ',', engine = 'python'))\n",
    "feat = processData(pd.read_csv('./daic_woz/dev_data/302/302_CLNF_features.txt', delimiter = ',', engine = 'python'))\n",
    "feat3d = processData(pd.read_csv('./daic_woz/dev_data/302/302_CLNF_features3D.txt', delimiter = ',', engine = 'python'))\n",
    "gaze = processData(pd.read_csv('./daic_woz/dev_data/302/302_CLNF_gaze.txt', delimiter = ',', engine = 'python'))\n",
    "pose = processData(pd.read_csv('./daic_woz/dev_data/302/302_CLNF_pose.txt', delimiter = ',', engine = 'python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 388])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_tensor(au, feat, feat3d, gaze, pose).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
